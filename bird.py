# -*- coding: utf-8 -*-
"""Bird.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bXwup0xmwWhVGkmZ7ixZ3AuNT9LNmEA4
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

data=pd.read_csv('bird-gps.csv')

data.info()

data.shape

data.columns

data.describe()

data.head(10)

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

# Scatter plot of latitude and longitude, colored by species
plt.figure(figsize=(12, 8))
sns.scatterplot(data=data, x='lon', y='lat', hue='species', palette='viridis', s=10)
plt.title('Geographical Distribution of Species')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.legend(title='Species', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

#Histogram of dive depths
plt.figure(figsize=(10, 6))
sns.histplot(data['max_depth.m'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Maximum Dive Depths')
plt.xlabel('Maximum Depth (m)')
plt.ylabel('Frequency')
plt.show()

#Count plot of bird species
plt.figure(figsize=(12, 8))
sns.countplot(y='species', data=data, palette='pastel')
plt.title('Count of Observations per Species')
plt.xlabel('Count')
plt.ylabel('Species')
plt.show()

#Line plot of dive activity over time
data['date_time'] = pd.to_datetime(data['date_time'])
data_time_series = data.set_index('date_time').resample('M').sum()
plt.figure(figsize=(12, 6))
sns.lineplot(data=data_time_series[['is_dive']], marker='o', dashes=False)
plt.title('Dive Activity Over Time')
plt.xlabel('Date')
plt.ylabel('Total Dive Activity')
plt.show()

#Heatmap of dive conditions
dive_conditions = data[['is_dive_1m', 'is_dive_2m', 'is_dive_4m', 'is_dive_5m', 'is_dive_0m']].mean().to_frame().T
plt.figure(figsize=(10, 6))
sns.heatmap(dive_conditions, annot=True, cmap='YlGnBu', cbar=True, fmt='.2%', linewidths=.5)
plt.title('Proportion of Dives at Different Depths')
plt.xlabel('Dive Condition')
plt.ylabel('')
plt.show()

"""Dive Prediction Model using Logistic Regression

Objective: Predict whether a bird will dive at a given time or location.
"""

data["coverage_ratio"].fillna(data["coverage_ratio"].mean(), inplace=True)

data["date_time"] = pd.to_datetime(data["date_time"])

# Extract features from datetime
data["year"] = data["date_time"].dt.year
data["month"] = data["date_time"].dt.month
data["day"] = data["date_time"].dt.day
data["hour"] = data["date_time"].dt.hour

# Print summary of preprocessed data
print(data.describe())

# Convert categorical columns to numeric
data["species"] = data["species"].astype('category').cat.codes

# Select features and target
features = ["lat", "lon", "alt", "unix", "bird", "species", "year", "month", "day", "hour", "max_depth.m", "colony2", "coverage_ratio"]
target = "is_dive"

# Split the data into train and test sets
X = data[features]
y = data[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train the model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

"""Time Series Forecasting using Neural Prophet

Objective: Forecast future values of bird activity metrics such as maximum depth or coverage ratio over time.
"""

pip install neuralprophet

import pandas as pd
from neuralprophet import NeuralProphet

data["date_time"] = pd.to_datetime(data["date_time"])

df = data[["date_time", "max_depth.m"]].rename(columns={"date_time": "ds", "max_depth.m": "y"})

df = df.groupby('ds').y.mean().reset_index()

model = NeuralProphet()

model.fit(df, freq='H')

future = model.make_future_dataframe(df, periods=365)

forecast = model.predict(future)

print(forecast.columns)

print(forecast[['ds', 'yhat1']])

import plotly.offline as py

# Plot the forecast
fig_forecast = model.plot(forecast)
py.iplot(fig_forecast)

# Plot the forecast components
fig_components = model.plot_components(forecast)
py.iplot(fig_components)